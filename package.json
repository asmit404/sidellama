{
  "name": "obsidian-ollama",
  "version": "1.0.0",
  "description": "Chat with local ML models using Ollama inside Obsidian",
  "main": "main.js",
  "scripts": {
    "dev": "node esbuild.config.mjs",
    "build": "tsc -noEmit -skipLibCheck && node esbuild.config.mjs production",
    "version": "node version-bump.mjs && git add manifest.json versions.json"
  },
  "repository": {
    "type": "git",
    "url": "git+https://github.com/asmit404/obsidian-ollama.git"
  },
  "keywords": [
    "obsidian",
    "obsidian-plugin",
    "ollama",
    "ai",
    "ml"
  ],
  "author": "",
  "license": "MIT",
  "bugs": {
    "url": "https://github.com/asmit404/obsidian-ollama/issues"
  },
  "homepage": "https://github.com/asmit404/obsidian-ollama#readme",
  "devDependencies": {
    "@types/node": "^20.11.5",
    "builtin-modules": "^5.0.0",
    "esbuild": "^0.20.0",
    "obsidian": "^1.4.11",
    "tslib": "^2.8.1",
    "typescript": "^5.3.3"
  }
}
